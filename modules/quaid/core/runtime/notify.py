#!/usr/bin/env python3
"""
User Notification Module

Channel-agnostic messaging to the user via the platform adapter.

Usage:
  python3 notify.py "Your message here"
  python3 notify.py --check  # Just show last channel info

Programmatic:
  from core.runtime.notify import notify_user, get_last_channel

  info = get_last_channel()
  if info:
      notify_user("Doc updated: janitor-reference.md")
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Optional

from lib.adapter import ChannelInfo
from lib.runtime_context import (
    get_install_url,
    get_last_channel as _ctx_get_last_channel,
    send_notification as _ctx_send_notification,
)

# Branding prefix for all notifications
QUAID_HEADER = "**[Quaid]**"
MAX_NOTIFY_CHARS = 3500


def _notify_full_text() -> bool:
    """Check if notifications should show full text (no truncation)."""
    try:
        from config import get_config
        return get_config().notifications.full_text
    except Exception:
        return False


def _check_janitor_health() -> Optional[str]:
    """Check if the janitor has run recently. Returns warning string or None.

    This is a lightweight DB check (single query, no LLM calls).
    Called during extraction notifications to alert the user if their
    janitor isn't running â€” e.g. misconfigured heartbeat, missing API key, etc.
    """
    try:
        from datetime import datetime, timedelta
        from datastore.facade import get_graph, get_last_successful_janitor_completed_at

        last_completed_at = get_last_successful_janitor_completed_at(get_graph())
        if not last_completed_at:
            return (
                "âš ï¸ **Janitor has never run.** New memories are pending review.\n"
                "Make sure the janitor is scheduled in your HEARTBEAT.md.\n"
                "It must be triggered by your bot."
            )

        last_run = datetime.fromisoformat(last_completed_at)
        hours_ago = (datetime.now() - last_run).total_seconds() / 3600

        if hours_ago > 72:
            return (
                f"âš ï¸ **Janitor hasn't run in {int(hours_ago)}h!** Memories are piling up.\n"
                "Check your HEARTBEAT.md schedule and ensure the bot can reach Quaid."
            )
        elif hours_ago > 48:
            return (
                f"âš ï¸ **Janitor last ran {int(hours_ago)}h ago.** "
                "Check your HEARTBEAT.md schedule if this is unexpected."
            )

        return None
    except Exception:
        return None  # Never crash extraction over a health check

def get_last_channel(session_key: str = "") -> Optional[ChannelInfo]:
    """Get the user's last active channel from session state (delegates to adapter)."""
    return _ctx_get_last_channel(session_key)


def _resolve_channel(feature: Optional[str] = None) -> Optional[str]:
    """Get the configured channel override for a notification feature.
    Returns None for 'last_used' (use session default), or a specific channel name."""
    if not feature:
        return None
    try:
        from config import get_config
        channel = get_config().notifications.effective_channel(feature)
        if channel and channel != "last_used":
            return channel
    except Exception:
        pass
    return None


def notify_user(
    message: str,
    session_key: str = "",
    dry_run: bool = False,
    channel_override: Optional[str] = None,
) -> bool:
    """Send a notification to the user (delegates to adapter).

    Args:
        message: Message to send
        session_key: Ignored (adapter manages sessions)
        dry_run: If True, print command but don't send
        channel_override: If set, send to this channel instead of the session's last channel.

    Returns:
        True if message sent successfully, False otherwise
    """
    return _ctx_send_notification(message, channel_override=channel_override, dry_run=dry_run)


def notify_doc_update(
    doc_path: str,
    trigger: str,
    summary: Optional[str] = None,
    dry_run: bool = False
) -> bool:
    """
    Notify user about a doc auto-update.

    Args:
        doc_path: Path to the updated doc
        trigger: What triggered the update (compact, janitor, manual)
        summary: Optional summary of changes
        dry_run: If True, don't actually send

    Returns:
        True if notification sent
    """
    # Extract just the filename for brevity
    doc_name = Path(doc_path).name

    # Map trigger to human-readable description
    trigger_desc = {
        "compact": "conversation compaction",
        "reset": "session reset",
        "janitor": "nightly maintenance",
        "manual": "manual request",
        "on-demand": "staleness detection",
    }.get(trigger, trigger)

    # Build message with header
    msg_parts = [
        f"{QUAID_HEADER} ğŸ“‹ **Auto-Documentation System Report**",
        "",
        f"Updated: `{doc_name}`",
        f"Trigger: {trigger_desc}",
    ]

    if summary:
        # Truncate summary if too long (unless fullText enabled)
        if not _notify_full_text() and len(summary) > 200:
            summary = summary[:197] + "..."
        msg_parts.append(f"Changes: {summary}")

    msg_parts.append("")
    msg_parts.append("_This doc was auto-updated to stay in sync with code changes._")

    message = "\n".join(msg_parts)

    return notify_user(message, dry_run=dry_run)


def notify_memory_recall(
    memories: list,
    min_similarity: int = 70,
    dry_run: bool = False,
    source_breakdown: Optional[dict] = None
) -> bool:
    """
    Notify user about memories being injected into context.

    Args:
        memories: List of memory dicts with 'text', 'similarity', and optionally 'via' fields
        min_similarity: Only show memories with similarity >= this (default 70%)
        dry_run: If True, don't actually send
        source_breakdown: Optional dict with vector_count, graph_count, pronoun_resolved, owner_person

    Returns:
        True if notification sent
    """
    if not memories:
        return False

    mode = ""
    if source_breakdown:
        mode = str(source_breakdown.get("mode", "")).strip().lower()
    effective_min_similarity = 0 if mode in {"auto_inject", "tool", "tool_call", "manual"} else min_similarity

    # Separate direct matches from graph discoveries
    direct_matches = []
    graph_discoveries = []
    low_confidence_count = 0
    full_text = _notify_full_text()

    for mem in memories:
        if isinstance(mem, dict):
            text = mem.get("text", str(mem))
            similarity = mem.get("similarity", 0)
            via = mem.get("via", "vector")
            category = str(mem.get("category", "")).strip().lower()
        else:
            text = str(mem)
            similarity = 0
            via = "vector"
            category = ""

        # Clean up the text
        text = " ".join(text.split())
        if not full_text and len(text) > 120:
            text = text[:117] + "..."

        if via == "graph":
            # Graph discoveries always show (they're relationships, not similarity-ranked)
            graph_discoveries.append(text)
        elif similarity >= effective_min_similarity:
            label = ""
            # Label graph-origin node hits explicitly; do not relabel normal vector facts/events.
            if via == "graph" and category in {"person", "concept", "event", "entity"}:
                label = f"graph-node/{category}"
            elif category and category not in {"fact", "preference", "decision", "relationship", "other"}:
                label = f"node/{category}"
            direct_matches.append((text, similarity, label))
        else:
            low_confidence_count += 1

    if not direct_matches and not graph_discoveries:
        # Nothing worth showing
        return False

    # Build notification message
    msg_parts = [f"{QUAID_HEADER} ğŸ§  **Memory Context Loaded:**", ""]

    if direct_matches:
        msg_parts.append("**Direct Matches:**")
        for text, similarity, label in direct_matches:
            if label:
                msg_parts.append(f"â€¢ [{similarity}%] [{label}] {text}")
            else:
                msg_parts.append(f"â€¢ [{similarity}%] {text}")

    if graph_discoveries:
        if direct_matches:
            msg_parts.append("")
        msg_parts.append("**Graph Discoveries:**")
        for text in graph_discoveries:
            msg_parts.append(f"â€¢ {text}")

    # Add source breakdown if provided
    if source_breakdown:
        msg_parts.append("")
        vector_count = source_breakdown.get("vector_count", len(direct_matches))
        graph_count = source_breakdown.get("graph_count", len(graph_discoveries))
        pronoun_resolved = source_breakdown.get("pronoun_resolved", False)
        query = source_breakdown.get("query", "")
        mode_label = ""
        if mode == "auto_inject":
            mode_label = "auto-inject"
        elif mode in ("tool", "tool_call", "manual"):
            mode_label = "tool recall"
        elif mode:
            mode_label = mode.replace("_", "-")
        if mode_label:
            msg_parts.append(f"_Mode: {mode_label}_")

        if query:
            msg_parts.append(f"_Query: \"{query}\"_")

        sources_line = f"_Sources: {vector_count} vector, {graph_count} graph"
        if pronoun_resolved:
            owner_person = source_breakdown.get("owner_person", "")
            if owner_person:
                sources_line += f" | Pronoun resolved: {owner_person}"
            else:
                sources_line += " | Pronoun: âœ“"
        sources_line += "_"
        msg_parts.append(sources_line)
    elif low_confidence_count > 0:
        msg_parts.append("")
        msg_parts.append(f"_({low_confidence_count} low-confidence facts filtered)_")

    message = "\n".join(msg_parts)

    return notify_user(message, dry_run=dry_run, channel_override=_resolve_channel("retrieval"))


def notify_docs_search(
    query: str,
    results: list,
    dry_run: bool = False
) -> bool:
    """
    Notify user about docs being searched.

    Args:
        query: The search query used
        results: List of result dicts with 'doc', 'section', 'score' fields
        dry_run: If True, don't actually send

    Returns:
        True if notification sent
    """
    if not results:
        return False

    msg_parts = [f"{QUAID_HEADER} ğŸ“š **Docs Search Results:**", ""]
    msg_parts.append(f"_Query: \"{query}\"_")
    msg_parts.append("")

    for r in results[:5]:  # Limit to top 5
        doc = r.get("doc", "unknown")
        section = r.get("section", "")
        score = r.get("score", 0)

        # Clean up section title
        if section:
            section = section[:60] + "..." if len(section) > 60 else section
            msg_parts.append(f"â€¢ `{doc}` â€” {section} ({int(score*100)}%)")
        else:
            msg_parts.append(f"â€¢ `{doc}` ({int(score*100)}%)")

    if len(results) > 5:
        msg_parts.append(f"_...and {len(results) - 5} more_")

    message = "\n".join(msg_parts)
    return notify_user(message, dry_run=dry_run)


def notify_memory_extraction(
    facts_stored: int,
    facts_skipped: int,
    edges_created: int,
    trigger: str = "extraction",
    details: Optional[list] = None,
    dry_run: bool = False,
    snippet_details: Optional[dict] = None,
    always_notify: bool = False,
) -> bool:
    """
    Notify user about memories extracted from conversation.

    Args:
        facts_stored: Number of facts successfully stored
        facts_skipped: Number of facts skipped (duplicates, too short, etc.)
        edges_created: Number of relationship edges created
        trigger: What triggered extraction ("compaction", "reset", etc.)
        details: Optional list of fact details [{text, status, reason?, edges?}]
        dry_run: If True, don't actually send
        snippet_details: Optional dict of soul snippets {filename: [snippet_text, ...]}

    Returns:
        True if notification sent
    """
    has_snippets = snippet_details and any(v for v in snippet_details.values())
    try:
        from config import get_config
        extraction_level = get_config().notifications.effective_level("extraction")
    except Exception:
        extraction_level = "summary"
    show_trigger = extraction_level == "full"
    no_results = (facts_stored == 0 and facts_skipped == 0 and edges_created == 0 and not details and not has_snippets)
    if not always_notify and not details and facts_stored == 0 and edges_created == 0 and not has_snippets:
        return False  # Nothing to report

    if always_notify and no_results:
        if show_trigger:
            trigger_label = {
                "compaction": "compaction",
                "reset": "reset",
                "timeout": "timeout",
                "extraction": "extraction",
                "new": "new",
            }.get(trigger, trigger)
            message = f"{QUAID_HEADER} ğŸ’¾ Memory Extraction ({trigger_label}): No facts found."
        else:
            message = f"{QUAID_HEADER} ğŸ’¾ Memory Extraction: No facts found."
        return notify_user(message, dry_run=dry_run, channel_override=_resolve_channel("extraction"))

    full_text = _notify_full_text()
    msg_parts = [f"{QUAID_HEADER} ğŸ’¾ **Memory Extraction:**", ""]

    # Trigger info (full verbosity only)
    if show_trigger:
        trigger_label = {
            "compaction": "Context compacted",
            "reset": "Session reset (/new)",
            "timeout": "Inactivity timeout",
            "extraction": "Extraction complete"
        }.get(trigger, trigger)
        msg_parts.append(f"_Trigger: {trigger_label}_")
        msg_parts.append("")

    # Summary stats
    msg_parts.append(f"**Summary:** {facts_stored} stored, {facts_skipped} skipped, {edges_created} edges")
    msg_parts.append("")

    # Detailed fact list
    if details:
        for i, fact in enumerate(details, 1):
            text = fact.get("text", "")
            status = fact.get("status", "unknown")
            reason = fact.get("reason", "")
            edges = fact.get("edges", [])

            # Truncate text for display (unless fullText enabled)
            display_text = text if full_text else (text[:80] + "..." if len(text) > 80 else text)

            # Status emoji
            if status == "stored":
                emoji = "âœ…"
            elif status == "updated":
                emoji = "ğŸ”„"
            elif status == "duplicate":
                emoji = "â­ï¸"
            elif status == "skipped":
                emoji = "âš ï¸"
            else:
                emoji = "âŒ"

            line = f"{emoji} {display_text}"

            # Add reason for skipped/duplicate
            if status == "duplicate" and reason:
                line += f"\n   â†³ _dup of: {reason}_"
            elif status == "skipped" and reason:
                line += f" _({reason})_"

            # Add edges
            if edges:
                for edge in edges:
                    line += f"\n   ğŸ“ {edge}"

            msg_parts.append(line)
            msg_parts.append("")

    # Journal entries section
    if has_snippets:
        msg_parts.append("âœ¨ **Journal Entries:**")
        msg_parts.append("")
        for filename, snippets in snippet_details.items():
            if snippets:
                entry_word = "entry" if len(snippets) == 1 else "entries"
                msg_parts.append(f"**{filename}** ({len(snippets)} {entry_word}):")
                for s in snippets:
                    display = s if full_text else (s[:120] + "..." if len(s) > 120 else s)
                    msg_parts.append(f"  ğŸ“ {display}")
                msg_parts.append("")

    message = "\n".join(msg_parts)
    channel = _resolve_channel("extraction")
    if len(message) <= MAX_NOTIFY_CHARS:
        return notify_user(message, dry_run=dry_run, channel_override=channel)

    # Some channels drop oversized messages; split so extraction details still arrive.
    lines = message.split("\n")
    chunks = []
    current_lines = []
    current_len = 0
    for line in lines:
        line_len = len(line) + 1
        if current_lines and (current_len + line_len > MAX_NOTIFY_CHARS):
            chunks.append("\n".join(current_lines))
            current_lines = []
            current_len = 0
        current_lines.append(line)
        current_len += line_len
    if current_lines:
        chunks.append("\n".join(current_lines))

    sent_any = False
    for idx, chunk in enumerate(chunks):
        if idx > 0:
            chunk = (
                f"{QUAID_HEADER} ğŸ’¾ **Memory Extraction (cont. {idx + 1}/{len(chunks)}):**\n\n"
                f"{chunk}"
            )
        if notify_user(chunk, dry_run=dry_run, channel_override=channel):
            sent_any = True
    return sent_any


def notify_janitor_summary(
    metrics: dict,
    applied_changes: dict,
    dry_run: bool = False
) -> bool:
    """
    Notify user about janitor run summary.

    Args:
        metrics: Dict with total_duration_seconds, llm_calls, errors, task_durations
        applied_changes: Dict with counts of changes made
        dry_run: If True, don't actually send

    Returns:
        True if notification sent
    """
    message = format_janitor_summary_message(metrics, applied_changes)
    return notify_user(message, dry_run=dry_run, channel_override=_resolve_channel("janitor"))


def format_janitor_summary_message(metrics: dict, applied_changes: dict) -> str:
    """Format janitor summary content for either direct or delayed delivery."""
    msg_parts = [f"{QUAID_HEADER} ğŸ§¹ **Nightly Janitor Complete:**", ""]

    # Duration and stats
    duration = metrics.get("total_duration_seconds", 0)
    if duration >= 60:
        msg_parts.append(f"â±ï¸ Duration: {duration/60:.1f}min")
    else:
        msg_parts.append(f"â±ï¸ Duration: {duration:.0f}s")

    llm_calls = metrics.get("llm_calls", 0)
    if llm_calls > 0:
        msg_parts.append(f"ğŸ¤– LLM calls: {llm_calls}")

    errors = metrics.get("errors", 0)
    if errors > 0:
        msg_parts.append(f"âŒ Errors: {errors}")

    msg_parts.append("")

    # Changes applied
    msg_parts.append("**Changes:**")
    change_labels = {
        "reviewed": "ğŸ“ Reviewed",
        "kept": "âœ… Kept",
        "deleted": "ğŸ—‘ï¸ Deleted",
        "fixed": "ğŸ”§ Fixed",
        "merged": "ğŸ”€ Merged",
        "edges_created": "ğŸ“ Edges created",
        "contradictions_found": "âš¡ Contradictions",
        "duplicates_rejected": "â­ï¸ Duplicates rejected",
        "decayed": "ğŸ“‰ Decayed",
    }

    has_changes = False
    for key, label in change_labels.items():
        count = applied_changes.get(key, 0)
        if count and count > 0:
            msg_parts.append(f"â€¢ {label}: {count}")
            has_changes = True

    if not has_changes:
        msg_parts.append("â€¢ No changes applied")

    # Contradiction decisions are always shown in full detail, regardless of verbosity.
    contradiction_findings = applied_changes.get("contradiction_findings") or []
    contradiction_decisions = applied_changes.get("contradiction_decisions") or []
    if contradiction_findings or contradiction_decisions:
        msg_parts.append("")
        msg_parts.append("**Contradiction Details (full):**")
        for f in contradiction_findings[:10]:
            if not isinstance(f, dict):
                continue
            msg_parts.append(f"â€¢ Found: \"{f.get('text_a', '')}\" â†” \"{f.get('text_b', '')}\"")
            msg_parts.append(f"  Reason: {f.get('reason', '')}")
        for d in contradiction_decisions[:15]:
            if not isinstance(d, dict):
                continue
            msg_parts.append(f"â€¢ Decision: {d.get('action', 'UNKNOWN')}")
            msg_parts.append(f"  A: {d.get('text_a', '')}")
            msg_parts.append(f"  B: {d.get('text_b', '')}")
            msg_parts.append(f"  Why: {d.get('reason', '')}")

    # Update alert â€” super visible at the end
    update_info = applied_changes.get("update_available")
    if isinstance(update_info, dict) and update_info.get("latest"):
        msg_parts.append("")
        msg_parts.append("âš ï¸âš ï¸âš ï¸ **UPDATE AVAILABLE** âš ï¸âš ï¸âš ï¸")
        msg_parts.append(f"v{update_info['current']} â†’ v{update_info['latest']}")
        msg_parts.append("")
        msg_parts.append("Update with:")
        msg_parts.append(f"`curl -fsSL {get_install_url()} | bash`")
        msg_parts.append(f"Release notes: {update_info.get('url', '')}")

    return "\n".join(msg_parts)


def notify_daily_memories(
    memories: list,
    dry_run: bool = False
) -> bool:
    """
    Notify user about memories created today.

    Args:
        memories: List of memory dicts with 'text', 'category', 'created_at'
        dry_run: If True, don't actually send

    Returns:
        True if notification sent
    """
    message = format_daily_memories_message(memories)
    if not message:
        return False
    return notify_user(message, dry_run=dry_run, channel_override=_resolve_channel("retrieval"))


def format_daily_memories_message(memories: list) -> Optional[str]:
    """Format daily memories digest for either direct or delayed delivery."""
    if not memories:
        return None

    full_text = _notify_full_text()
    msg_parts = [f"{QUAID_HEADER} ğŸ“š **Today's New Memories:**", ""]
    msg_parts.append(f"_{len(memories)} memories added today_")
    msg_parts.append("")

    # Group by category
    by_category: dict = {}
    for mem in memories:
        cat = mem.get("category", "fact")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(mem)

    # Category emojis
    cat_emoji = {
        "fact": "ğŸ“Œ",
        "preference": "ğŸ’¡",
        "relationship": "ğŸ‘¥",
        "decision": "ğŸ¯",
        "other": "ğŸ“"
    }

    for cat, mems in by_category.items():
        emoji = cat_emoji.get(cat, "ğŸ“")
        msg_parts.append(f"**{emoji} {cat.title()}** ({len(mems)})")
        for mem in mems[:10]:  # Limit per category
            text = mem.get("text", "")
            # Truncate (unless fullText enabled)
            if not full_text and len(text) > 100:
                text = text[:97] + "..."
            msg_parts.append(f"â€¢ {text}")
        if len(mems) > 10:
            msg_parts.append(f"  _...and {len(mems) - 10} more_")
        msg_parts.append("")

    return "\n".join(msg_parts)


def main():
    parser = argparse.ArgumentParser(
        description="Send notifications to user's last active channel"
    )
    parser.add_argument(
        "message",
        nargs="?",
        help="Message to send"
    )
    parser.add_argument(
        "--check",
        action="store_true",
        help="Just show last channel info, don't send"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Print command but don't send"
    )
    parser.add_argument(
        "--session",
        default="",
        help="Session key (default: adapter-managed)"
    )

    args = parser.parse_args()

    if args.check:
        info = get_last_channel(args.session)
        if info:
            print(f"Channel: {info.channel}")
            print(f"Target: {info.target}")
            print(f"Account: {info.account_id}")
            print(f"Session: {info.session_key}")
        else:
            print("No last channel found")
            sys.exit(1)
        return

    if not args.message:
        parser.error("Message required (or use --check)")

    success = notify_user(args.message, args.session, args.dry_run)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
